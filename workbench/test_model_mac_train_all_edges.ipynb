{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable CUDA debugging\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.set_device(1)  # Use GPU 1\n",
    "\n",
    "# # Verify that the correct GPU is being used\n",
    "# if torch.cuda.is_available():\n",
    "#     current_device = torch.cuda.current_device()\n",
    "#     print(f\"Using GPU: {torch.cuda.get_device_name(current_device)}\")\n",
    "#     print(f\"Device ID: {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load node features\n",
    "s_df = pd.read_csv('/data/servilla/DT_HGNN/Model/Nodes/s_emb_full_183.csv', index_col=0)  # Substrates CSV file\n",
    "p_df = pd.read_csv('//data/servilla/DT_HGNN/Model/Nodes/p_emb_full_237197.csv', index_col=0)  # Combined proteins CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load node features\n",
    "# s_df = pd.read_csv('/data/servilla/DT_HGNN/Model/Nodes/No_text_nodes/s_emb_no_text_183.csv', index_col=0)  # Substrates CSV file\n",
    "# proteins_df = pd.read_csv('/data/servilla/DT_HGNN/Model/Nodes/No_text_nodes/p_emb_no_text_237197.csv', index_col=0)  # Combined proteins CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load node features\n",
    "# s_df = pd.read_csv('/data/servilla/DT_HGNN/Model/Nodes/s_emb_full_183.csv', index_col=0)  # Substrates CSV file\n",
    "# proteins_df = pd.read_csv('/data/servilla/DT_HGNN/Model/Nodes/Zero_Features_Nodes/p_emb_filtered _0.csv', index_col=0)  # Combined proteins CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1526</th>\n",
       "      <th>1527</th>\n",
       "      <th>1528</th>\n",
       "      <th>1529</th>\n",
       "      <th>1530</th>\n",
       "      <th>1531</th>\n",
       "      <th>1532</th>\n",
       "      <th>1533</th>\n",
       "      <th>1534</th>\n",
       "      <th>1535</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChEBI ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHEBI:30616</th>\n",
       "      <td>0.455800</td>\n",
       "      <td>0.268283</td>\n",
       "      <td>-0.306537</td>\n",
       "      <td>0.050826</td>\n",
       "      <td>-0.386505</td>\n",
       "      <td>-0.471963</td>\n",
       "      <td>-0.836031</td>\n",
       "      <td>-0.192729</td>\n",
       "      <td>-1.156560</td>\n",
       "      <td>-0.272351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480035</td>\n",
       "      <td>-0.456548</td>\n",
       "      <td>-0.099031</td>\n",
       "      <td>-0.462904</td>\n",
       "      <td>-0.471903</td>\n",
       "      <td>-0.142393</td>\n",
       "      <td>-0.475653</td>\n",
       "      <td>-0.365997</td>\n",
       "      <td>-0.848439</td>\n",
       "      <td>-0.244717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEBI:64837</th>\n",
       "      <td>0.615461</td>\n",
       "      <td>0.182076</td>\n",
       "      <td>-0.157183</td>\n",
       "      <td>-0.101461</td>\n",
       "      <td>-0.146697</td>\n",
       "      <td>-0.613957</td>\n",
       "      <td>-0.450166</td>\n",
       "      <td>-0.183678</td>\n",
       "      <td>-0.624151</td>\n",
       "      <td>-0.271550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107556</td>\n",
       "      <td>-0.293493</td>\n",
       "      <td>-0.117009</td>\n",
       "      <td>0.133840</td>\n",
       "      <td>-0.734478</td>\n",
       "      <td>-0.017846</td>\n",
       "      <td>-0.497699</td>\n",
       "      <td>0.045008</td>\n",
       "      <td>-0.386243</td>\n",
       "      <td>-0.474938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEBI:58245</th>\n",
       "      <td>0.506397</td>\n",
       "      <td>0.400621</td>\n",
       "      <td>0.064001</td>\n",
       "      <td>-0.252644</td>\n",
       "      <td>-0.300555</td>\n",
       "      <td>-0.395209</td>\n",
       "      <td>-0.638782</td>\n",
       "      <td>-0.311317</td>\n",
       "      <td>-1.088331</td>\n",
       "      <td>-0.142135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350439</td>\n",
       "      <td>-0.128131</td>\n",
       "      <td>-0.003493</td>\n",
       "      <td>-0.408475</td>\n",
       "      <td>-0.426437</td>\n",
       "      <td>-0.205415</td>\n",
       "      <td>-0.840490</td>\n",
       "      <td>-0.568522</td>\n",
       "      <td>-0.887295</td>\n",
       "      <td>-0.210402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEBI:57673</th>\n",
       "      <td>0.438195</td>\n",
       "      <td>0.195334</td>\n",
       "      <td>0.072717</td>\n",
       "      <td>-0.337968</td>\n",
       "      <td>-0.261332</td>\n",
       "      <td>-0.498841</td>\n",
       "      <td>-0.686211</td>\n",
       "      <td>-0.416058</td>\n",
       "      <td>-0.848771</td>\n",
       "      <td>-0.195883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379729</td>\n",
       "      <td>-0.210616</td>\n",
       "      <td>0.100455</td>\n",
       "      <td>-0.483885</td>\n",
       "      <td>-0.470335</td>\n",
       "      <td>-0.155050</td>\n",
       "      <td>-0.884785</td>\n",
       "      <td>-0.499907</td>\n",
       "      <td>-0.748851</td>\n",
       "      <td>-0.243686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEBI:58115</th>\n",
       "      <td>0.263242</td>\n",
       "      <td>0.269032</td>\n",
       "      <td>0.145805</td>\n",
       "      <td>-0.515321</td>\n",
       "      <td>-0.187021</td>\n",
       "      <td>-0.480719</td>\n",
       "      <td>-0.610310</td>\n",
       "      <td>-0.469400</td>\n",
       "      <td>-0.936680</td>\n",
       "      <td>-0.147377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176869</td>\n",
       "      <td>-0.017013</td>\n",
       "      <td>0.130641</td>\n",
       "      <td>-0.251108</td>\n",
       "      <td>-0.505997</td>\n",
       "      <td>0.049098</td>\n",
       "      <td>-0.935488</td>\n",
       "      <td>-0.402900</td>\n",
       "      <td>-1.060279</td>\n",
       "      <td>-0.297512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEBI:17821</th>\n",
       "      <td>0.023680</td>\n",
       "      <td>0.181743</td>\n",
       "      <td>-0.468458</td>\n",
       "      <td>-0.544133</td>\n",
       "      <td>-0.462411</td>\n",
       "      <td>-0.216898</td>\n",
       "      <td>-0.611499</td>\n",
       "      <td>-0.537903</td>\n",
       "      <td>-1.444201</td>\n",
       "      <td>-0.396138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192647</td>\n",
       "      <td>0.243999</td>\n",
       "      <td>-0.094861</td>\n",
       "      <td>-0.463224</td>\n",
       "      <td>-0.749601</td>\n",
       "      <td>-0.850797</td>\n",
       "      <td>0.202593</td>\n",
       "      <td>-0.268341</td>\n",
       "      <td>-0.374329</td>\n",
       "      <td>-0.572429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEBI:16708</th>\n",
       "      <td>0.096989</td>\n",
       "      <td>0.625387</td>\n",
       "      <td>-0.322925</td>\n",
       "      <td>-0.704778</td>\n",
       "      <td>-0.569291</td>\n",
       "      <td>-0.014360</td>\n",
       "      <td>-0.661434</td>\n",
       "      <td>-0.700171</td>\n",
       "      <td>-1.437007</td>\n",
       "      <td>0.076964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350745</td>\n",
       "      <td>0.274081</td>\n",
       "      <td>-0.197719</td>\n",
       "      <td>-0.049403</td>\n",
       "      <td>-0.751242</td>\n",
       "      <td>-0.279356</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>-0.010360</td>\n",
       "      <td>0.142680</td>\n",
       "      <td>-0.341658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEBI:16040</th>\n",
       "      <td>0.621236</td>\n",
       "      <td>0.530406</td>\n",
       "      <td>-0.460275</td>\n",
       "      <td>-0.801638</td>\n",
       "      <td>-0.524102</td>\n",
       "      <td>-0.129895</td>\n",
       "      <td>-0.411074</td>\n",
       "      <td>-0.879548</td>\n",
       "      <td>-1.166363</td>\n",
       "      <td>-0.003238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412461</td>\n",
       "      <td>0.175881</td>\n",
       "      <td>-0.243160</td>\n",
       "      <td>-0.114933</td>\n",
       "      <td>-0.512422</td>\n",
       "      <td>-0.668245</td>\n",
       "      <td>0.257403</td>\n",
       "      <td>-0.211986</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>-0.508171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEBI:17712</th>\n",
       "      <td>-0.107732</td>\n",
       "      <td>0.336747</td>\n",
       "      <td>-0.038453</td>\n",
       "      <td>-0.642287</td>\n",
       "      <td>-0.252473</td>\n",
       "      <td>0.018258</td>\n",
       "      <td>-0.603322</td>\n",
       "      <td>-0.706207</td>\n",
       "      <td>-1.430682</td>\n",
       "      <td>-0.389253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712826</td>\n",
       "      <td>0.254684</td>\n",
       "      <td>-0.383512</td>\n",
       "      <td>-0.324324</td>\n",
       "      <td>-0.801045</td>\n",
       "      <td>-0.449467</td>\n",
       "      <td>0.379588</td>\n",
       "      <td>0.021359</td>\n",
       "      <td>-0.069705</td>\n",
       "      <td>-0.390515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEBI:57947</th>\n",
       "      <td>0.405691</td>\n",
       "      <td>-0.262620</td>\n",
       "      <td>-0.551576</td>\n",
       "      <td>-0.355275</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>-0.249656</td>\n",
       "      <td>-0.803515</td>\n",
       "      <td>-0.191274</td>\n",
       "      <td>-0.921245</td>\n",
       "      <td>-0.311669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306338</td>\n",
       "      <td>-0.753978</td>\n",
       "      <td>-0.385797</td>\n",
       "      <td>-0.565311</td>\n",
       "      <td>-0.385584</td>\n",
       "      <td>-0.081249</td>\n",
       "      <td>-0.032753</td>\n",
       "      <td>-0.187163</td>\n",
       "      <td>-0.248556</td>\n",
       "      <td>-0.393803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 1536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5  \\\n",
       "ChEBI ID                                                                  \n",
       "CHEBI:30616  0.455800  0.268283 -0.306537  0.050826 -0.386505 -0.471963   \n",
       "CHEBI:64837  0.615461  0.182076 -0.157183 -0.101461 -0.146697 -0.613957   \n",
       "CHEBI:58245  0.506397  0.400621  0.064001 -0.252644 -0.300555 -0.395209   \n",
       "CHEBI:57673  0.438195  0.195334  0.072717 -0.337968 -0.261332 -0.498841   \n",
       "CHEBI:58115  0.263242  0.269032  0.145805 -0.515321 -0.187021 -0.480719   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "CHEBI:17821  0.023680  0.181743 -0.468458 -0.544133 -0.462411 -0.216898   \n",
       "CHEBI:16708  0.096989  0.625387 -0.322925 -0.704778 -0.569291 -0.014360   \n",
       "CHEBI:16040  0.621236  0.530406 -0.460275 -0.801638 -0.524102 -0.129895   \n",
       "CHEBI:17712 -0.107732  0.336747 -0.038453 -0.642287 -0.252473  0.018258   \n",
       "CHEBI:57947  0.405691 -0.262620 -0.551576 -0.355275  0.510200 -0.249656   \n",
       "\n",
       "                    6         7         8         9  ...      1526      1527  \\\n",
       "ChEBI ID                                             ...                       \n",
       "CHEBI:30616 -0.836031 -0.192729 -1.156560 -0.272351  ...  0.480035 -0.456548   \n",
       "CHEBI:64837 -0.450166 -0.183678 -0.624151 -0.271550  ...  0.107556 -0.293493   \n",
       "CHEBI:58245 -0.638782 -0.311317 -1.088331 -0.142135  ...  0.350439 -0.128131   \n",
       "CHEBI:57673 -0.686211 -0.416058 -0.848771 -0.195883  ...  0.379729 -0.210616   \n",
       "CHEBI:58115 -0.610310 -0.469400 -0.936680 -0.147377  ...  0.176869 -0.017013   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "CHEBI:17821 -0.611499 -0.537903 -1.444201 -0.396138  ...  0.192647  0.243999   \n",
       "CHEBI:16708 -0.661434 -0.700171 -1.437007  0.076964  ...  0.350745  0.274081   \n",
       "CHEBI:16040 -0.411074 -0.879548 -1.166363 -0.003238  ...  0.412461  0.175881   \n",
       "CHEBI:17712 -0.603322 -0.706207 -1.430682 -0.389253  ...  0.712826  0.254684   \n",
       "CHEBI:57947 -0.803515 -0.191274 -0.921245 -0.311669  ...  0.306338 -0.753978   \n",
       "\n",
       "                 1528      1529      1530      1531      1532      1533  \\\n",
       "ChEBI ID                                                                  \n",
       "CHEBI:30616 -0.099031 -0.462904 -0.471903 -0.142393 -0.475653 -0.365997   \n",
       "CHEBI:64837 -0.117009  0.133840 -0.734478 -0.017846 -0.497699  0.045008   \n",
       "CHEBI:58245 -0.003493 -0.408475 -0.426437 -0.205415 -0.840490 -0.568522   \n",
       "CHEBI:57673  0.100455 -0.483885 -0.470335 -0.155050 -0.884785 -0.499907   \n",
       "CHEBI:58115  0.130641 -0.251108 -0.505997  0.049098 -0.935488 -0.402900   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "CHEBI:17821 -0.094861 -0.463224 -0.749601 -0.850797  0.202593 -0.268341   \n",
       "CHEBI:16708 -0.197719 -0.049403 -0.751242 -0.279356  0.015822 -0.010360   \n",
       "CHEBI:16040 -0.243160 -0.114933 -0.512422 -0.668245  0.257403 -0.211986   \n",
       "CHEBI:17712 -0.383512 -0.324324 -0.801045 -0.449467  0.379588  0.021359   \n",
       "CHEBI:57947 -0.385797 -0.565311 -0.385584 -0.081249 -0.032753 -0.187163   \n",
       "\n",
       "                 1534      1535  \n",
       "ChEBI ID                         \n",
       "CHEBI:30616 -0.848439 -0.244717  \n",
       "CHEBI:64837 -0.386243 -0.474938  \n",
       "CHEBI:58245 -0.887295 -0.210402  \n",
       "CHEBI:57673 -0.748851 -0.243686  \n",
       "CHEBI:58115 -1.060279 -0.297512  \n",
       "...               ...       ...  \n",
       "CHEBI:17821 -0.374329 -0.572429  \n",
       "CHEBI:16708  0.142680 -0.341658  \n",
       "CHEBI:16040  0.005222 -0.508171  \n",
       "CHEBI:17712 -0.069705 -0.390515  \n",
       "CHEBI:57947 -0.248556 -0.393803  \n",
       "\n",
       "[183 rows x 1536 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniprot ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A0A061ACU2</th>\n",
       "      <td>-0.006915</td>\n",
       "      <td>0.017029</td>\n",
       "      <td>-0.012460</td>\n",
       "      <td>0.009969</td>\n",
       "      <td>-0.034116</td>\n",
       "      <td>-0.067283</td>\n",
       "      <td>0.063458</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>-0.022449</td>\n",
       "      <td>0.050131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055087</td>\n",
       "      <td>-0.014889</td>\n",
       "      <td>-0.111876</td>\n",
       "      <td>-0.341646</td>\n",
       "      <td>-0.072502</td>\n",
       "      <td>-0.323306</td>\n",
       "      <td>-0.056634</td>\n",
       "      <td>0.290476</td>\n",
       "      <td>-0.039389</td>\n",
       "      <td>0.168516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A061AE05</th>\n",
       "      <td>0.035674</td>\n",
       "      <td>-0.022189</td>\n",
       "      <td>-0.009367</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>-0.069653</td>\n",
       "      <td>-0.014517</td>\n",
       "      <td>0.044575</td>\n",
       "      <td>-0.132423</td>\n",
       "      <td>-0.021363</td>\n",
       "      <td>-0.007532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.163456</td>\n",
       "      <td>-0.056955</td>\n",
       "      <td>-0.099271</td>\n",
       "      <td>-0.458213</td>\n",
       "      <td>-0.038014</td>\n",
       "      <td>-0.183186</td>\n",
       "      <td>-0.225026</td>\n",
       "      <td>0.419967</td>\n",
       "      <td>-0.160937</td>\n",
       "      <td>0.212690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A061I403</th>\n",
       "      <td>0.053080</td>\n",
       "      <td>-0.078657</td>\n",
       "      <td>0.038157</td>\n",
       "      <td>-0.005594</td>\n",
       "      <td>-0.030804</td>\n",
       "      <td>-0.007899</td>\n",
       "      <td>-0.074586</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.045537</td>\n",
       "      <td>0.027765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089691</td>\n",
       "      <td>0.042491</td>\n",
       "      <td>-0.139474</td>\n",
       "      <td>-0.520852</td>\n",
       "      <td>0.032338</td>\n",
       "      <td>-0.228753</td>\n",
       "      <td>-0.163234</td>\n",
       "      <td>0.391762</td>\n",
       "      <td>-0.193620</td>\n",
       "      <td>0.197258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A072ULZ1</th>\n",
       "      <td>0.061750</td>\n",
       "      <td>-0.051334</td>\n",
       "      <td>-0.038662</td>\n",
       "      <td>0.045027</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>-0.051204</td>\n",
       "      <td>0.090917</td>\n",
       "      <td>-0.132791</td>\n",
       "      <td>-0.079478</td>\n",
       "      <td>0.076762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156411</td>\n",
       "      <td>0.033456</td>\n",
       "      <td>-0.092049</td>\n",
       "      <td>-0.477360</td>\n",
       "      <td>0.118776</td>\n",
       "      <td>-0.227023</td>\n",
       "      <td>-0.209066</td>\n",
       "      <td>0.333932</td>\n",
       "      <td>-0.138006</td>\n",
       "      <td>0.150505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A0A072VDF2</th>\n",
       "      <td>-0.039073</td>\n",
       "      <td>-0.042116</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.026522</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>-0.040989</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>-0.054791</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.048461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137038</td>\n",
       "      <td>0.013142</td>\n",
       "      <td>-0.135132</td>\n",
       "      <td>-0.456653</td>\n",
       "      <td>0.051990</td>\n",
       "      <td>-0.205040</td>\n",
       "      <td>-0.102661</td>\n",
       "      <td>0.373307</td>\n",
       "      <td>-0.127597</td>\n",
       "      <td>0.118297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9ZU96</th>\n",
       "      <td>-0.039020</td>\n",
       "      <td>-0.071629</td>\n",
       "      <td>-0.052520</td>\n",
       "      <td>0.034033</td>\n",
       "      <td>-0.092409</td>\n",
       "      <td>-0.087255</td>\n",
       "      <td>0.029642</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>-0.055408</td>\n",
       "      <td>0.074894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011945</td>\n",
       "      <td>0.051887</td>\n",
       "      <td>-0.091516</td>\n",
       "      <td>-0.475149</td>\n",
       "      <td>0.043887</td>\n",
       "      <td>-0.123123</td>\n",
       "      <td>0.027734</td>\n",
       "      <td>0.276535</td>\n",
       "      <td>-0.114138</td>\n",
       "      <td>0.146494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9ZUH0</th>\n",
       "      <td>-0.045847</td>\n",
       "      <td>-0.016646</td>\n",
       "      <td>0.028537</td>\n",
       "      <td>0.077879</td>\n",
       "      <td>-0.114865</td>\n",
       "      <td>0.026522</td>\n",
       "      <td>-0.045645</td>\n",
       "      <td>0.133281</td>\n",
       "      <td>-0.005342</td>\n",
       "      <td>0.116256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038638</td>\n",
       "      <td>0.073979</td>\n",
       "      <td>-0.087714</td>\n",
       "      <td>-0.357490</td>\n",
       "      <td>0.032010</td>\n",
       "      <td>-0.088160</td>\n",
       "      <td>-0.005223</td>\n",
       "      <td>0.335018</td>\n",
       "      <td>-0.271940</td>\n",
       "      <td>0.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9ZUU2</th>\n",
       "      <td>0.056914</td>\n",
       "      <td>-0.073989</td>\n",
       "      <td>-0.014398</td>\n",
       "      <td>0.084379</td>\n",
       "      <td>0.026393</td>\n",
       "      <td>-0.043069</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>-0.078882</td>\n",
       "      <td>0.044475</td>\n",
       "      <td>0.130091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.040818</td>\n",
       "      <td>-0.086419</td>\n",
       "      <td>-0.396256</td>\n",
       "      <td>0.071960</td>\n",
       "      <td>-0.125251</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.308530</td>\n",
       "      <td>-0.165650</td>\n",
       "      <td>0.108122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9ZV78</th>\n",
       "      <td>-0.058564</td>\n",
       "      <td>-0.061872</td>\n",
       "      <td>-0.019513</td>\n",
       "      <td>0.037072</td>\n",
       "      <td>-0.151353</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>-0.034898</td>\n",
       "      <td>0.019487</td>\n",
       "      <td>-0.091470</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050338</td>\n",
       "      <td>0.055201</td>\n",
       "      <td>-0.097549</td>\n",
       "      <td>-0.334631</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>-0.079912</td>\n",
       "      <td>-0.044114</td>\n",
       "      <td>0.311552</td>\n",
       "      <td>-0.235891</td>\n",
       "      <td>0.070714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9ZWC6</th>\n",
       "      <td>0.016220</td>\n",
       "      <td>-0.030860</td>\n",
       "      <td>-0.003680</td>\n",
       "      <td>0.068048</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>-0.038501</td>\n",
       "      <td>0.034696</td>\n",
       "      <td>0.034682</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.098071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008939</td>\n",
       "      <td>0.075425</td>\n",
       "      <td>-0.099178</td>\n",
       "      <td>-0.396726</td>\n",
       "      <td>0.069776</td>\n",
       "      <td>-0.136350</td>\n",
       "      <td>-0.084443</td>\n",
       "      <td>0.360020</td>\n",
       "      <td>-0.240535</td>\n",
       "      <td>0.126099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237197 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5  \\\n",
       "Uniprot ID                                                               \n",
       "A0A061ACU2 -0.006915  0.017029 -0.012460  0.009969 -0.034116 -0.067283   \n",
       "A0A061AE05  0.035674 -0.022189 -0.009367 -0.004829 -0.069653 -0.014517   \n",
       "A0A061I403  0.053080 -0.078657  0.038157 -0.005594 -0.030804 -0.007899   \n",
       "A0A072ULZ1  0.061750 -0.051334 -0.038662  0.045027 -0.004024 -0.051204   \n",
       "A0A072VDF2 -0.039073 -0.042116  0.003819  0.026522  0.000374 -0.040989   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "Q9ZU96     -0.039020 -0.071629 -0.052520  0.034033 -0.092409 -0.087255   \n",
       "Q9ZUH0     -0.045847 -0.016646  0.028537  0.077879 -0.114865  0.026522   \n",
       "Q9ZUU2      0.056914 -0.073989 -0.014398  0.084379  0.026393 -0.043069   \n",
       "Q9ZV78     -0.058564 -0.061872 -0.019513  0.037072 -0.151353  0.017346   \n",
       "Q9ZWC6      0.016220 -0.030860 -0.003680  0.068048  0.001295 -0.038501   \n",
       "\n",
       "                   6         7         8         9  ...      2038      2039  \\\n",
       "Uniprot ID                                          ...                       \n",
       "A0A061ACU2  0.063458  0.032882 -0.022449  0.050131  ... -0.055087 -0.014889   \n",
       "A0A061AE05  0.044575 -0.132423 -0.021363 -0.007532  ... -0.163456 -0.056955   \n",
       "A0A061I403 -0.074586 -0.035587 -0.045537  0.027765  ... -0.089691  0.042491   \n",
       "A0A072ULZ1  0.090917 -0.132791 -0.079478  0.076762  ... -0.156411  0.033456   \n",
       "A0A072VDF2  0.012172 -0.054791  0.003940  0.048461  ... -0.137038  0.013142   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "Q9ZU96      0.029642  0.003676 -0.055408  0.074894  ... -0.011945  0.051887   \n",
       "Q9ZUH0     -0.045645  0.133281 -0.005342  0.116256  ...  0.038638  0.073979   \n",
       "Q9ZUU2      0.006505 -0.078882  0.044475  0.130091  ...  0.009835  0.040818   \n",
       "Q9ZV78     -0.034898  0.019487 -0.091470  0.010800  ...  0.050338  0.055201   \n",
       "Q9ZWC6      0.034696  0.034682  0.001938  0.098071  ... -0.008939  0.075425   \n",
       "\n",
       "                2040      2041      2042      2043      2044      2045  \\\n",
       "Uniprot ID                                                               \n",
       "A0A061ACU2 -0.111876 -0.341646 -0.072502 -0.323306 -0.056634  0.290476   \n",
       "A0A061AE05 -0.099271 -0.458213 -0.038014 -0.183186 -0.225026  0.419967   \n",
       "A0A061I403 -0.139474 -0.520852  0.032338 -0.228753 -0.163234  0.391762   \n",
       "A0A072ULZ1 -0.092049 -0.477360  0.118776 -0.227023 -0.209066  0.333932   \n",
       "A0A072VDF2 -0.135132 -0.456653  0.051990 -0.205040 -0.102661  0.373307   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "Q9ZU96     -0.091516 -0.475149  0.043887 -0.123123  0.027734  0.276535   \n",
       "Q9ZUH0     -0.087714 -0.357490  0.032010 -0.088160 -0.005223  0.335018   \n",
       "Q9ZUU2     -0.086419 -0.396256  0.071960 -0.125251  0.028300  0.308530   \n",
       "Q9ZV78     -0.097549 -0.334631  0.041178 -0.079912 -0.044114  0.311552   \n",
       "Q9ZWC6     -0.099178 -0.396726  0.069776 -0.136350 -0.084443  0.360020   \n",
       "\n",
       "                2046      2047  \n",
       "Uniprot ID                      \n",
       "A0A061ACU2 -0.039389  0.168516  \n",
       "A0A061AE05 -0.160937  0.212690  \n",
       "A0A061I403 -0.193620  0.197258  \n",
       "A0A072ULZ1 -0.138006  0.150505  \n",
       "A0A072VDF2 -0.127597  0.118297  \n",
       "...              ...       ...  \n",
       "Q9ZU96     -0.114138  0.146494  \n",
       "Q9ZUH0     -0.271940  0.066000  \n",
       "Q9ZUU2     -0.165650  0.108122  \n",
       "Q9ZV78     -0.235891  0.070714  \n",
       "Q9ZWC6     -0.240535  0.126099  \n",
       "\n",
       "[237197 rows x 2048 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load edges\n",
    "tp_s_df = pd.read_csv('/data/servilla/DT_HGNN/Model/Edges/distributed_combined_tp_s_edges_13340.csv')\n",
    "ppi_df = pd.read_csv('/data/servilla/DT_HGNN/Model/Edges/combined_ppi_edges_full.csv')\n",
    "ssi_df = pd.read_csv('/data/servilla/DT_HGNN/Model/Edges/combined_ssi_edges_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect and clean the data\n",
    "def inspect_and_clean(df):\n",
    "    non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns\n",
    "    print(f\"Non-numeric columns: {non_numeric_columns}\")\n",
    "    if len(non_numeric_columns) > 0:\n",
    "        df[non_numeric_columns] = df[non_numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns: Index([], dtype='object')\n",
      "Non-numeric columns: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "s_df = inspect_and_clean(s_df)\n",
    "p_df = inspect_and_clean(p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to numpy arrays\n",
    "s_features = s_df.values\n",
    "p_features = p_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_features shape: (183, 1536)\n",
      "p_features shape: (237197, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes to ensure correct dimensions\n",
    "print(f\"s_features shape: {s_features.shape}\")  # Expected (183, 1536), no KD (212, 768)\n",
    "print(f\"p_features shape: {p_features.shape}\")  # Expected (some number, 2048), no KD (571609, 1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use GPU 1\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features (normalizes columns to have mean 0 and variance 1)\n",
    "s_features = (s_features - np.mean(s_features, axis=0)) / np.std(s_features, axis=0)\n",
    "p_features = (p_features - np.mean(p_features, axis=0)) / np.std(p_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation layers, changes the number of features 1536 -> 2048\n",
    "# for substrates and 2048 -> 2048 for proteins. The transform_p layer is useful \n",
    "# for transforming the feature representation within the same dimensional space,\n",
    "#  y = Wx + b.\n",
    "\n",
    "device = torch.device('cpu')  # Temporarily switch to CPU\n",
    "\n",
    "\n",
    "transform_s = Linear(1536, 2048).to(device) # Change depending on the number of features\n",
    "transform_p = Linear(2048, 2048).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transformations in batches, this can be useful when dealing with large \n",
    "# datasets that may not fit into memory or GPU all at once. \n",
    "def transform_in_batches(features, transform_layer, batch_size=10000):\n",
    "    num_samples = features.shape[0]\n",
    "    print(f\"Number of samples: {num_samples}\")\n",
    "    transformed_features = []\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch = features[i:i + batch_size]\n",
    "        batch_tensor = torch.tensor(batch, dtype=torch.float).to(device)\n",
    "        transformed_batch = transform_layer(batch_tensor)\n",
    "        transformed_features.append(transformed_batch.detach().cpu().numpy())  # Use detach() before numpy()\n",
    "    return np.vstack(transformed_features) # Stack arrays in sequence vertically (row wise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 183\n",
      "Number of samples: 237197\n"
     ]
    }
   ],
   "source": [
    "s_features_transformed = transform_in_batches(s_features, transform_s)\n",
    "p_features_transformed = transform_in_batches(p_features, transform_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to tensors\n",
    "s_features_tensor = torch.tensor(s_features_transformed, dtype=torch.float).to(device)\n",
    "p_features_tensor = torch.tensor(p_features_transformed, dtype=torch.float).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features, vertically stacks features (dim=0) to create a single tensor\n",
    "all_features = torch.cat([p_features_tensor, s_features_tensor], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_ids = set(p_df.index)\n",
    "substrate_ids = set(s_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, train_size=0.8, val_size=0.1, test_size=0.1):\n",
    "    # Split into train and temp (80% train, 20% temp)\n",
    "    train_df, temp_df = train_test_split(df, train_size=train_size, random_state=42)\n",
    "    \n",
    "    # Calculate the size for validation and test splits\n",
    "    val_test_ratio = val_size / (val_size + test_size)  # 50% of temp goes to validation and 50% to test\n",
    "\n",
    "    # Split temp into validation and test (10% each)\n",
    "    val_df, test_df = train_test_split(temp_df, train_size=val_test_ratio, random_state=42)\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for each edge type\n",
    "ppi_train_df, ppi_val_df, ppi_test_df = split_data(ppi_df)\n",
    "ssi_train_df, ssi_val_df, ssi_test_df = split_data(ssi_df)\n",
    "tp_s_train_df, tp_s_val_df, tp_s_test_df = split_data(tp_s_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22326</th>\n",
       "      <td>B5Z8R5</td>\n",
       "      <td>CHEBI:17757</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24868</th>\n",
       "      <td>Q2J6N1</td>\n",
       "      <td>CHEBI:16389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15236</th>\n",
       "      <td>P24981</td>\n",
       "      <td>CHEBI:132124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>P30750</td>\n",
       "      <td>CHEBI:57926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230</th>\n",
       "      <td>C3P1E2</td>\n",
       "      <td>CHEBI:41509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>Q8FAV1</td>\n",
       "      <td>CHEBI:15378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>P0A437</td>\n",
       "      <td>CHEBI:16813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Q1I7Z8</td>\n",
       "      <td>CHEBI:132124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>A1XGU4</td>\n",
       "      <td>CHEBI:132124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>P0DA07</td>\n",
       "      <td>CHEBI:58116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21344 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source        target  label\n",
       "22326  B5Z8R5   CHEBI:17757      0\n",
       "24868  Q2J6N1   CHEBI:16389      0\n",
       "15236  P24981  CHEBI:132124      0\n",
       "20396  P30750   CHEBI:57926      0\n",
       "20230  C3P1E2   CHEBI:41509      0\n",
       "...       ...           ...    ...\n",
       "21575  Q8FAV1   CHEBI:15378      0\n",
       "5390   P0A437   CHEBI:16813      1\n",
       "860    Q1I7Z8  CHEBI:132124      1\n",
       "15795  A1XGU4  CHEBI:132124      0\n",
       "23654  P0DA07   CHEBI:58116      0\n",
       "\n",
       "[21344 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_s_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate mappings\n",
    "protein_mapping = {node_id: i for i, node_id in enumerate(p_df.index)}\n",
    "substrate_mapping = {node_id: i for i, node_id in enumerate(s_df.index)}\n",
    "\n",
    "# Helper function to apply the correct mapping\n",
    "def apply_correct_mapping(df, source_mapping, target_mapping):\n",
    "    df['source'] = df['source'].map(source_mapping)\n",
    "    df['target'] = df['target'].map(target_mapping)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply the correct mappings\n",
    "tp_s_train_df = apply_correct_mapping(tp_s_train_df, protein_mapping, substrate_mapping)\n",
    "tp_s_val_df = apply_correct_mapping(tp_s_val_df, protein_mapping, substrate_mapping)\n",
    "tp_s_test_df = apply_correct_mapping(tp_s_test_df, protein_mapping, substrate_mapping)\n",
    "\n",
    "ppi_train_df = apply_correct_mapping(ppi_train_df, protein_mapping, protein_mapping)\n",
    "ppi_val_df = apply_correct_mapping(ppi_val_df, protein_mapping, protein_mapping)\n",
    "ppi_test_df = apply_correct_mapping(ppi_test_df, protein_mapping, protein_mapping)\n",
    "\n",
    "ssi_train_df = apply_correct_mapping(ssi_train_df, substrate_mapping, substrate_mapping)\n",
    "ssi_val_df = apply_correct_mapping(ssi_val_df, substrate_mapping, substrate_mapping)\n",
    "ssi_test_df = apply_correct_mapping(ssi_test_df, substrate_mapping, substrate_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_s_full_df = apply_correct_mapping(tp_s_df, protein_mapping, substrate_mapping)\n",
    "ppi_full_df = apply_correct_mapping(ppi_df, protein_mapping, protein_mapping)\n",
    "ssi_full_df = apply_correct_mapping(ssi_df, substrate_mapping, substrate_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       source  target  label\n",
      "0      110150       0      1\n",
      "1      113110       0      1\n",
      "2       94944      63      1\n",
      "3       86624      63      1\n",
      "4      132714       0      1\n",
      "...       ...     ...    ...\n",
      "26675  118949      18      0\n",
      "26676   87873       0      0\n",
      "26677   88009      19      0\n",
      "26678   97381      63      0\n",
      "26679  148748      63      0\n",
      "\n",
      "[26680 rows x 3 columns]\n",
      "          source  target  label\n",
      "0         157025  225772      1\n",
      "1         187416  234940      1\n",
      "2         234940  187416      1\n",
      "3         225772  100854      1\n",
      "4         225772  157025      1\n",
      "...          ...     ...    ...\n",
      "13327041  106801   24539      0\n",
      "13327042  106199  133771      0\n",
      "13327043   98851   90276      0\n",
      "13327044  191132   11958      0\n",
      "13327045  229284  226859      0\n",
      "\n",
      "[13327046 rows x 3 columns]\n",
      "      source  target  label\n",
      "0         89      17      1\n",
      "1         17      89      1\n",
      "2         99      78      1\n",
      "3         78      99      1\n",
      "4         19     129      1\n",
      "...      ...     ...    ...\n",
      "4349      71      33      0\n",
      "4350      92      97      0\n",
      "4351     140     145      0\n",
      "4352      24     153      0\n",
      "4353      86      81      0\n",
      "\n",
      "[4354 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tp_s_full_df)\n",
    "print(ppi_full_df)\n",
    "print(ssi_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edge index tensors\n",
    "train_edges_tp_s = torch.tensor(tp_s_train_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "val_edges_tp_s = torch.tensor(tp_s_val_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "test_edges_tp_s = torch.tensor(tp_s_test_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "\n",
    "train_edges_ppi = torch.tensor(ppi_train_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "val_edges_ppi = torch.tensor(ppi_val_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "test_edges_ppi = torch.tensor(ppi_test_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "\n",
    "train_edges_ssi = torch.tensor(ssi_train_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "val_edges_ssi = torch.tensor(ssi_val_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "test_edges_ssi = torch.tensor(ssi_test_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "\n",
    "# Convert the labels to tensors\n",
    "train_labels_tp_s = torch.tensor(tp_s_train_df['label'].values, dtype=torch.float)\n",
    "val_labels_tp_s = torch.tensor(tp_s_val_df['label'].values, dtype=torch.float)\n",
    "test_labels_tp_s = torch.tensor(tp_s_test_df['label'].values, dtype=torch.float)\n",
    "\n",
    "train_labels_ppi = torch.tensor(ppi_train_df['label'].values, dtype=torch.float)\n",
    "val_labels_ppi = torch.tensor(ppi_val_df['label'].values, dtype=torch.float)\n",
    "test_labels_ppi = torch.tensor(ppi_test_df['label'].values, dtype=torch.float)\n",
    "\n",
    "train_labels_ssi = torch.tensor(ssi_train_df['label'].values, dtype=torch.float)\n",
    "val_labels_ssi = torch.tensor(ssi_val_df['label'].values, dtype=torch.float)\n",
    "test_labels_ssi = torch.tensor(ssi_test_df['label'].values, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tp_s_full_df = tp_s_full_df[tp_s_full_df['label'] == 1]\n",
    "\n",
    "\n",
    "positive_ppi_full_df = ppi_full_df[ppi_full_df['label'] == 1]\n",
    "\n",
    "\n",
    "positive_ssi_full_df = ssi_full_df[ssi_full_df['label'] == 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_positive_edges_tp_s = torch.tensor(positive_tp_s_full_df[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "full_positive_edges_ppi = torch.tensor(positive_ppi_full_df[['source', 'target']].values, dtype=torch.long).t().contiguous()\n",
    "full_positive_edges_ssi = torch.tensor(positive_ssi_full_df[['source', 'target']].values, dtype=torch.long).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tp_s_train_df = tp_s_train_df[tp_s_train_df['label'] == 1]\n",
    "\n",
    "train_edges_tp_s_positive = torch.tensor(positive_tp_s_train_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "\n",
    "positive_ppi_train_df = ppi_train_df[ppi_train_df['label'] == 1]\n",
    "\n",
    "train_edges_ppi_positive = torch.tensor(positive_ppi_train_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "\n",
    "positive_ssi_train_df = ssi_train_df[ssi_train_df['label'] == 1]\n",
    "\n",
    "train_edges_ssi_positive = torch.tensor(positive_ssi_train_df[['source', 'target']].values.T, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 13340])\n"
     ]
    }
   ],
   "source": [
    "print(full_positive_edges_tp_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the percentage of edges to remove\n",
    "ppi_removal_percentage = 1.0  # Remove 20% of PPI edges\n",
    "ssi_removal_percentage = 1.0  # Remove 20% of SSI edges\n",
    "tp_s_removal_percentage = 1.0  # Remove 20% of tp_s edges\n",
    "\n",
    "\n",
    "# Function to remove a percentage of edges\n",
    "def remove_edges(edges, removal_percentage):\n",
    "    num_edges = edges.size(1)\n",
    "    num_to_remove = int(removal_percentage * num_edges)\n",
    "    indices_to_keep = torch.randperm(num_edges)[:-num_to_remove]  # Randomly select edges to keep\n",
    "    return edges[:, indices_to_keep]\n",
    "\n",
    "# Remove a percentage of PPI edges\n",
    "train_edges_ppi_positive_reduced = remove_edges(train_edges_ppi_positive, ppi_removal_percentage)\n",
    "\n",
    "# Remove a percentage of SSI edges\n",
    "train_edges_ssi_positive_reduced = remove_edges(train_edges_ssi_positive, ssi_removal_percentage)\n",
    "\n",
    "# Remove a percentage of tp_s edges\n",
    "train_edges_tp_s_positive_reduced = remove_edges(train_edges_tp_s_positive, tp_s_removal_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Assign node features\n",
    "data['protein'].x = p_features_tensor\n",
    "data['substrate'].x = s_features_tensor\n",
    "\n",
    "# # Assign training edges\n",
    "data['protein', 'interacts_with', 'substrate'].edge_index = full_positive_edges_tp_s\n",
    "data['protein', 'interacts_with', 'protein'].edge_index = full_positive_edges_ppi\n",
    "data['substrate', 'interacts_with', 'substrate'].edge_index = full_positive_edges_ssi\n",
    "\n",
    "# # Assign training edges\n",
    "# data['protein', 'interacts_with', 'substrate'].edge_index = train_edges_tp_s\n",
    "# data['protein', 'interacts_with', 'protein'].edge_index = train_edges_ppi_positive\n",
    "# data['substrate', 'interacts_with', 'substrate'].edge_index = train_edges_ssi_positive\n",
    "\n",
    "# # Assign training edges\n",
    "# data['protein', 'interacts_with', 'substrate'].edge_index = train_edges_tp_s_positive_reduced\n",
    "# data['protein', 'interacts_with', 'protein'].edge_index = train_edges_ppi_positive_reduced\n",
    "# data['substrate', 'interacts_with', 'substrate'].edge_index = train_edges_ssi_positive_reduced\n",
    "\n",
    "# # Assign training edges\n",
    "# data['protein', 'interacts_with', 'substrate'].edge_index = train_edges_tp_s\n",
    "# data['protein', 'interacts_with', 'protein'].edge_index = train_edges_ppi\n",
    "# data['substrate', 'interacts_with', 'substrate'].edge_index = train_edges_ssi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the dictionary as a .pkl file\n",
    "with open('/data/servilla/DT_HGNN/Model/pkl_Files/x_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(data.x_dict, f)\n",
    "\n",
    "with open('/data/servilla/DT_HGNN/Model/pkl_Files/edge_index_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(data.edge_index_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"p_features tensor shape: {p_features_tensor.shape}\")\n",
    "print(f\"s_features tensor shape: {s_features_tensor.shape}\")\n",
    "print(f\"full edges tp_s shape: {full_edges_tp_s.shape}\")\n",
    "print(f\"positive train edges ppi shape: {full_edges_ppi.shape}\")\n",
    "print(f\"positive train edges ssi shape: {train_edges_ssi_positive.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_features tensor shape: torch.Size([237197, 2048])\n",
      "s_features tensor shape: torch.Size([183, 2048])\n",
      "positive train edges tp_s shape: torch.Size([2, 10651])\n",
      "positive train edges ppi shape: torch.Size([2, 5331163])\n",
      "positive train edges ssi shape: torch.Size([2, 1718])\n"
     ]
    }
   ],
   "source": [
    "print(f\"p_features tensor shape: {p_features_tensor.shape}\")\n",
    "print(f\"s_features tensor shape: {s_features_tensor.shape}\")\n",
    "print(f\"positive train edges tp_s shape: {train_edges_tp_s_positive.shape}\")\n",
    "print(f\"positive train edges ppi shape: {train_edges_ppi_positive.shape}\")\n",
    "print(f\"positive train edges ssi shape: {train_edges_ssi_positive.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_features tensor shape: torch.Size([237197, 2048])\n",
      "s_features tensor shape: torch.Size([183, 2048])\n",
      "positive train edges tp_s reduced shape: torch.Size([2, 0])\n",
      "positive train edges ppi reduced shape: torch.Size([2, 0])\n",
      "positive train edges ssi reduced shape: torch.Size([2, 0])\n"
     ]
    }
   ],
   "source": [
    "print(f\"p_features tensor shape: {p_features_tensor.shape}\")\n",
    "print(f\"s_features tensor shape: {s_features_tensor.shape}\")\n",
    "print(f\"positive train edges tp_s reduced shape: {train_edges_tp_s_positive_reduced.shape}\")\n",
    "print(f\"positive train edges ppi reduced shape: {train_edges_ppi_positive_reduced.shape}\")\n",
    "print(f\"positive train edges ssi reduced shape: {train_edges_ssi_positive_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "class GCNLinkPredictor(nn.Module):\n",
    "    def __init__(self, protein_dim, substrate_dim, hidden_channels):\n",
    "        super(GCNLinkPredictor, self).__init__()\n",
    "        self.protein_conv1 = GCNConv(protein_dim, hidden_channels)\n",
    "        self.substrate_conv1 = GCNConv(substrate_dim, hidden_channels)\n",
    "        self.protein_conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.substrate_conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        # GCN layer for tp_s interactions\n",
    "        self.tp_s_conv = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.link_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "    # Copy the encode function from the working model\n",
    "    def encode(self, x_dict, edge_index_dict):\n",
    "        # Use ppi edges to update protein embeddings\n",
    "        z_protein = self.protein_conv1(x_dict['protein'], edge_index_dict[('protein', 'interacts_with', 'protein')])\n",
    "        z_protein = self.protein_conv2(z_protein, edge_index_dict[('protein', 'interacts_with', 'protein')])\n",
    "\n",
    "        # Use ssi edges to update substrate embeddings\n",
    "        z_substrate = self.substrate_conv1(x_dict['substrate'], edge_index_dict[('substrate', 'interacts_with', 'substrate')])\n",
    "        z_substrate = self.substrate_conv2(z_substrate, edge_index_dict[('substrate', 'interacts_with', 'substrate')])\n",
    "        \n",
    "        # Use tp_s edges to update embeddings\n",
    "        edge_indices = edge_index_dict[('protein', 'interacts_with', 'substrate')]\n",
    "        protein_indices = edge_indices[0]\n",
    "        substrate_indices = edge_indices[1]\n",
    "\n",
    "        z_protein_tp_s = self.protein_conv1(x_dict['protein'], torch.stack([protein_indices, protein_indices], dim=0))\n",
    "        z_substrate_tp_s = self.substrate_conv1(x_dict['substrate'], torch.stack([substrate_indices, substrate_indices], dim=0))\n",
    "\n",
    "        z_protein += z_protein_tp_s\n",
    "        z_substrate += z_substrate_tp_s\n",
    "\n",
    "        return z_protein, z_substrate\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edges):\n",
    "        z_protein, z_substrate = self.encode(x_dict, edge_index_dict)\n",
    "        z_combined = torch.cat([z_protein[edges[0]], z_substrate[edges[1]]], dim=-1)\n",
    "        return self.link_predictor(z_combined).squeeze()\n",
    "\n",
    "# Initialize the model (ADJUST DIMENSIONS HERE!!!!!!!)\n",
    "model = GCNLinkPredictor(protein_dim=2048, substrate_dim=2048, hidden_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10  # Number of epochs to wait before stopping if no improvement\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)\n",
    "\n",
    "\n",
    "# Assuming `data` contains x_dict and edge_index_dict\n",
    "x_dict = data.x_dict\n",
    "edge_index_dict = data.edge_index_dict\n",
    "\n",
    "def train(x_dict, edge_index_dict, train_edges_tp_s, train_labels_tp_s):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass with all edges\n",
    "    z_protein, z_substrate = model.encode(x_dict, edge_index_dict)\n",
    "    \n",
    "    # For loss, only use tp_s edges\n",
    "    z_combined = torch.cat([z_protein[train_edges_tp_s[0]], z_substrate[train_edges_tp_s[1]]], dim=-1)\n",
    "    out = model.link_predictor(z_combined).squeeze()\n",
    "    \n",
    "    # Calculate loss only for tp_s edges\n",
    "    loss = criterion(out, train_labels_tp_s)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), out.detach()\n",
    "\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x_dict, data.edge_index_dict, val_edges_tp_s)\n",
    "        loss = criterion(out, val_labels_tp_s)\n",
    "    return loss.item(), out\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x_dict, data.edge_index_dict, test_edges_tp_s)\n",
    "        loss = criterion(out, test_labels_tp_s)\n",
    "    return loss.item(), out\n",
    "\n",
    "# Calculate additional metrics\n",
    "def calculate_metrics(labels, preds):\n",
    "    preds = torch.sigmoid(preds).cpu().numpy()\n",
    "    preds_binary = (preds > 0.5).astype(int)\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds_binary)\n",
    "    precision = precision_score(labels, preds_binary)\n",
    "    recall = recall_score(labels, preds_binary)\n",
    "    f1 = f1_score(labels, preds_binary)\n",
    "    auc = roc_auc_score(labels, preds)\n",
    "\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "# Modify the training loop to include metric calculation and visualization\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 800\n",
    "for epoch in range(epochs):\n",
    "    # Training step\n",
    "    train_loss, train_preds = train(x_dict, edge_index_dict, train_edges_tp_s, train_labels_tp_s)\n",
    "    # Validation step\n",
    "    val_loss, val_preds = validate()\n",
    "\n",
    "    # Store losses\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    accuracy, precision, recall, f1, auc = calculate_metrics(val_labels_tp_s, val_preds)\n",
    "    val_accuracies.append(accuracy)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, \"\n",
    "          f\"Val Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, \"\n",
    "          f\"F1: {f1:.4f}, AUC: {auc:.4f}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "    # Step the LR scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), '/data/servilla/DT_HGNN/data/Models_saves/best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    \n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('/data/servilla/DT_HGNN/data/Models_saves/best_model.pth'))\n",
    "\n",
    "# Testing\n",
    "test_loss, test_preds = test()\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = calculate_metrics(test_labels_tp_s, test_preds)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}, AUC: {test_auc:.4f}\")\n",
    "\n",
    "# Step 4: Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Plot validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START AUPRC TESTING HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "class GCNLinkPredictor(nn.Module):\n",
    "    def __init__(self, protein_dim, substrate_dim, hidden_channels):\n",
    "        super(GCNLinkPredictor, self).__init__()\n",
    "        self.protein_conv1 = GCNConv(protein_dim, hidden_channels)\n",
    "        self.substrate_conv1 = GCNConv(substrate_dim, hidden_channels)\n",
    "        self.protein_conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.substrate_conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        # GCN layer for tp_s interactions\n",
    "        self.tp_s_conv = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        self.link_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "    # Copy the encode function from the working model\n",
    "    def encode(self, x_dict, edge_index_dict):\n",
    "        # Use ppi edges to update protein embeddings\n",
    "        z_protein = self.protein_conv1(x_dict['protein'], edge_index_dict[('protein', 'interacts_with', 'protein')])\n",
    "        z_protein = self.protein_conv2(z_protein, edge_index_dict[('protein', 'interacts_with', 'protein')])\n",
    "\n",
    "        # Use ssi edges to update substrate embeddings\n",
    "        z_substrate = self.substrate_conv1(x_dict['substrate'], edge_index_dict[('substrate', 'interacts_with', 'substrate')])\n",
    "        z_substrate = self.substrate_conv2(z_substrate, edge_index_dict[('substrate', 'interacts_with', 'substrate')])\n",
    "        \n",
    "        # Use tp_s edges to update embeddings\n",
    "        edge_indices = edge_index_dict[('protein', 'interacts_with', 'substrate')]\n",
    "        protein_indices = edge_indices[0]\n",
    "        substrate_indices = edge_indices[1]\n",
    "\n",
    "        z_protein_tp_s = self.protein_conv1(x_dict['protein'], torch.stack([protein_indices, protein_indices], dim=0))\n",
    "        z_substrate_tp_s = self.substrate_conv1(x_dict['substrate'], torch.stack([substrate_indices, substrate_indices], dim=0))\n",
    "\n",
    "        z_protein += z_protein_tp_s\n",
    "        z_substrate += z_substrate_tp_s\n",
    "\n",
    "        return z_protein, z_substrate\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edges):\n",
    "        z_protein, z_substrate = self.encode(x_dict, edge_index_dict)\n",
    "        z_combined = torch.cat([z_protein[edges[0]], z_substrate[edges[1]]], dim=-1)\n",
    "        return self.link_predictor(z_combined).squeeze()\n",
    "\n",
    "# Initialize the model (ADJUST DIMENSIONS HERE!!!!!!!)\n",
    "model = GCNLinkPredictor(protein_dim=2048, substrate_dim=2048, hidden_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 10  # Number of epochs to wait before stopping if no improvement\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)\n",
    "\n",
    "\n",
    "# Assuming `data` contains x_dict and edge_index_dict\n",
    "x_dict = data.x_dict\n",
    "edge_index_dict = data.edge_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteins: [105249, 59389, 112387, 199741, 132320, 146918, 148764, 138323, 141230, 111150, 121088, 191202, 86195, 115928, 90981, 108390, 145404, 88355, 2215, 190388, 125705, 19538, 117685, 89632, 74872, 117455, 73297, 110731, 25756, 228325, 53606, 106600, 91721, 126844, 195962, 159392, 29391, 2165, 200018, 107318, 115102, 152978, 30451, 82414, 121598, 110148, 119954, 118698, 86810, 114307, 119897, 80221, 120677, 17189, 115807, 74227, 81260, 172327, 200796, 94291, 8783, 83600, 135537, 80308, 97975, 114723, 103695, 85503, 86196, 177650, 89347, 128642, 149161, 136723, 163521, 143781, 121216, 70558, 153858, 166922, 127456, 128780, 110003, 208202, 122063, 183926, 124231, 77951, 150231, 103342, 110124, 162976, 149705, 138722, 133317, 85998, 152599, 125605, 142105, 78421, 148340, 113987, 97034, 152639, 104981, 41788, 108015, 137132, 155371, 132073, 113348, 65236, 12592, 135352, 118408, 89392, 82796, 84238, 110509, 148015, 103604, 106306, 132955, 74218, 114007, 118004, 134684, 115392, 184810, 132614, 142858, 80425, 181249, 119001, 92558, 80593, 133696, 211584, 137606, 148781, 149987, 93089, 85235, 85787, 100122, 152493, 116828, 119075, 96108, 136426, 106440, 119505, 96989, 164278, 134181, 106487, 118609, 80795, 171354, 19543, 122200, 78234, 110466, 73886, 119007, 112165, 100308, 132647, 91436, 119841, 107508, 119011, 117326, 91171, 128903, 140922, 78343, 97695, 1609, 81284, 96640, 131845, 155373, 55312, 153801, 147382, 88, 76805, 106307, 222788, 181255, 121103, 106515, 130740, 107684, 130328, 145558, 106419, 111439, 110161, 85469, 109211, 118944, 175902, 111224, 92545, 110908, 102982, 18665, 110113, 85901, 107587, 129452, 107891, 201191, 118637, 103399, 106989, 196670, 128671, 65336, 107157, 135606, 12396, 207409, 89613, 121289, 109477, 91169, 17034, 127278, 76477, 132037, 115703, 133693, 76460, 25308, 49610, 160872, 132041, 87999, 85966, 143531, 128361, 136311, 202847, 86590, 61665, 95356, 108163, 109693, 108767, 104990, 99585, 135032, 125502, 102937, 211583, 98832, 89005, 134655, 25174, 162243, 110133, 213759, 107628, 109770, 160086, 101964, 126267, 122201, 92537, 111830, 228323, 126688, 90255, 25595, 68340, 138313, 220339, 198195, 150236, 127184, 86723, 81135, 84195, 115118, 160384, 124348, 137586, 92543, 111801, 76867, 97675, 146214, 167817, 171551, 116562, 7058, 3527, 143076, 141814, 86728, 81879, 196721, 222371, 91759, 91410, 188633, 154376, 132106, 141004, 116262, 111392, 97662, 31973, 130327, 84157, 84766, 181870, 4689, 82901, 149166, 109329, 78751, 87227, 111696, 85020, 130323, 114251, 129149, 121938, 97390, 118426, 86622, 84632, 86446, 144784, 106918, 88387, 126975, 220558, 75971, 112520, 172113, 23978, 166348, 96005, 144159, 130305, 130660, 108719, 115098, 153821, 97664, 115454, 80298, 139670, 126690, 154293, 55349, 117318, 168328, 84003, 28295, 149015, 185630, 121110, 88358, 130405, 135026, 125947, 97412, 104138, 86453, 183507, 36874, 148576, 192345, 8213, 40409, 131826, 105870, 48608, 161603, 73618, 175414, 89606, 104134, 57725, 95510, 143562, 84620, 119848, 104745, 153290, 127343, 86618, 97616, 106927, 123037, 82120, 132623, 155338, 150611, 108448, 76874, 84611, 199611, 88984, 144114, 110661, 91071, 97032, 111810, 129292, 91498, 104142, 114308, 130312, 12529, 74219, 54430, 122651, 130925, 78407, 128888, 41205, 202840, 105653, 145894, 103855, 132109, 144069, 114565, 106135, 111022, 119847, 113986, 100501, 79230, 105055, 54090, 146864, 83611, 93119, 110126, 89391, 110533, 129560, 157202, 89614, 201050, 104581, 3618, 84004, 96178, 33245, 119031, 106961, 91927, 78760, 129886, 126007, 64502, 75885, 137125, 43542, 87059, 152937, 88893, 86684, 87546, 138102, 115417, 195659, 143713, 124951, 118957, 111387, 90087, 14636, 73454, 93413, 129299, 128678, 134551, 102981, 132641, 74925, 107611, 78098, 89633, 229891, 108036, 91339, 121947, 149983, 148747, 96184, 114305, 74358, 111108, 17171, 113183, 116523, 97984, 110893, 108805, 109771, 91405, 81165, 50323, 150257, 105450, 88342, 115823, 143747, 91727, 78458, 76779, 81248, 176110, 104556, 105336, 150635, 55131, 108699, 44105, 60044, 117810, 10952, 49060, 139690, 128308, 153824, 137609, 463, 87202, 110954, 20085, 174822, 106317, 200281, 86024, 136728, 123035, 89888, 157183, 219671, 168353, 96346, 87666, 122852, 171696, 153831, 7064, 134654, 159387, 89424, 162665, 89663, 27736, 142038, 88186, 80803, 76010, 89881, 4445, 113815, 95693, 116840, 17553, 89009, 106294, 140828, 92097, 83299, 122199, 140297, 96163, 2399, 122196, 194706, 89381, 150008, 87223, 109108, 214459, 74829, 220048, 149756, 94432, 208767, 135638, 121287, 110268, 135517, 78837, 132624, 81283, 142088, 87660, 158668, 90942, 93092, 80963, 38634, 93330, 128673, 187903, 44142, 181253, 88653, 104557, 91203, 201193, 117939, 132103, 140270, 139298, 160496, 79805, 125958, 147801, 108778, 83463, 82865, 63996, 134333, 43771, 97370, 159547, 76933, 111840, 149639, 181783, 118409, 97890, 174331, 119005, 83950, 59357, 111560, 80726, 129557, 121105, 110435, 120005, 127254, 116144, 156742, 145898, 110144, 33770, 216825, 153842, 80962, 144920, 148730, 66528, 80715, 108722, 113567, 216103, 15131, 18620, 90020, 84601, 82866, 130664, 115704, 80781, 90727, 117274, 122621, 49694, 105684, 125625, 217103, 142175, 145092, 119148, 25115, 125454, 132619, 88350, 110108, 116813, 132101, 74449, 181742, 68014, 89448, 149805, 102938, 134681, 227603, 98509, 138390, 132776, 119485, 106133, 158620, 90250, 188494, 84784, 116606, 48640, 75310, 233159, 53081, 115822, 82974, 92331, 200798, 142045, 110102, 143720, 185964, 148087, 11328, 130273, 86189, 156396, 10689, 76585, 111050, 110001, 122070, 112182, 134688, 80714, 127261, 97001, 62096, 153003, 115679, 91438, 117290, 82630, 78378, 118628, 65137, 28938, 113779, 135010, 9268, 176109]\n",
      "Substrate 0 AUPRC: 0.8117, AUC: 0.3400\n",
      "Proteins: [149986, 116260, 215940, 28544, 110108, 153189, 135643, 132650, 89312, 85609, 84614, 9333, 103313, 110103, 86741]\n",
      "Substrate 1 AUPRC: 0.0762, AUC: 0.1867\n",
      "Proteins: [14460]\n",
      "Substrate 3 AUPRC: 0.0054, AUC: 0.0900\n",
      "Proteins: [62071, 14460]\n",
      "Substrate 4 AUPRC: 0.0115, AUC: 0.1900\n",
      "Proteins: [198939, 147563, 137958, 97783, 127964, 33118, 26892, 122165, 132432, 89603, 210825, 24745, 10690, 6058, 19871, 138154, 22053, 203556, 135497, 124577, 106592, 2263, 86727]\n",
      "Substrate 8 AUPRC: 0.1346, AUC: 0.3357\n",
      "Proteins: [40791]\n",
      "Substrate 9 AUPRC: 0.0063, AUC: 0.2200\n",
      "Proteins: [82111, 129568]\n",
      "Substrate 10 AUPRC: 0.0099, AUC: 0.0150\n",
      "Proteins: [13017, 27532, 10691]\n",
      "Substrate 11 AUPRC: 0.0149, AUC: 0.0333\n",
      "Proteins: [33515]\n",
      "Substrate 12 AUPRC: 0.0052, AUC: 0.0500\n",
      "Proteins: [125949]\n",
      "Substrate 13 AUPRC: 0.0060, AUC: 0.1700\n",
      "Proteins: [17165, 80977]\n",
      "Substrate 15 AUPRC: 0.0128, AUC: 0.2800\n",
      "Proteins: [223798, 227216, 144298, 5828, 3285, 52243]\n",
      "Substrate 16 AUPRC: 0.0311, AUC: 0.1317\n",
      "Proteins: [188480, 24351, 198288, 98202, 130622, 12581, 183708]\n",
      "Substrate 18 AUPRC: 0.0371, AUC: 0.1629\n",
      "Proteins: [163522, 228464, 121956, 195177, 83460, 146502, 76044, 92460, 84519, 166144, 72845, 168580, 176110, 143531, 226979, 132106, 14733, 103308, 34470, 155336, 125456, 191196, 84337, 85160, 111800, 130649, 108163, 144487, 278, 167428, 97386, 132958, 129582, 85357, 155919, 98328, 115704, 150232, 104996, 18667, 171354, 73297, 31210, 9723, 81261, 114960, 8334, 113232, 17189, 138105, 79473, 38784, 125945, 223398, 37379, 176097, 78874, 194642, 80226, 40352, 117363, 96005, 134936, 188480, 104564, 106273, 8325, 106959, 121943, 10460, 105679, 69115, 103507]\n",
      "Substrate 19 AUPRC: 0.4361, AUC: 0.4255\n",
      "Proteins: [56038]\n",
      "Substrate 20 AUPRC: 0.0068, AUC: 0.2800\n",
      "Proteins: [115290, 113413, 146401, 143421, 72412, 126979, 86297, 130552, 150108]\n",
      "Substrate 22 AUPRC: 0.0508, AUC: 0.2444\n",
      "Proteins: [58822, 149051, 114139, 44437, 33825, 45830, 139807, 25595, 116823, 149040, 56559, 56825]\n",
      "Substrate 23 AUPRC: 0.0620, AUC: 0.1858\n",
      "Proteins: [11941, 9891]\n",
      "Substrate 27 AUPRC: 0.0113, AUC: 0.1300\n",
      "Proteins: [70300]\n",
      "Substrate 28 AUPRC: 0.0128, AUC: 0.6200\n",
      "Proteins: [15438, 47637]\n",
      "Substrate 29 AUPRC: 0.5210, AUC: 0.8300\n",
      "Proteins: [93125, 118004, 86620, 25025, 8925]\n",
      "Substrate 31 AUPRC: 0.0326, AUC: 0.3220\n",
      "Proteins: [126203]\n",
      "Substrate 32 AUPRC: 0.0059, AUC: 0.1600\n",
      "Proteins: [38929, 63823, 126564]\n",
      "Substrate 33 AUPRC: 0.0170, AUC: 0.2067\n",
      "Proteins: [100566, 186116, 158428, 222374]\n",
      "Substrate 34 AUPRC: 0.0223, AUC: 0.1850\n",
      "Proteins: [152913, 114069, 1681, 114073]\n",
      "Substrate 35 AUPRC: 0.0229, AUC: 0.2200\n",
      "Proteins: [28718, 175312, 86196, 190542, 130418, 134515, 172505, 167973, 106288, 189201, 18619, 121292, 128353, 19539, 181240, 20213, 132283, 127265, 26239, 130622, 78447, 64297, 21228, 63721, 5137, 29464, 149799, 192760, 91066, 24290, 173829, 82410, 97783]\n",
      "Substrate 36 AUPRC: 0.1590, AUC: 0.2397\n",
      "Proteins: [131340, 81485, 10940, 205157, 89627, 157722, 94869, 35773, 151626, 101956, 91082, 64297, 118257, 111484, 220045, 8327, 140080, 107603, 3823, 126975, 65888, 104144, 56393, 65982, 64830, 125667, 74523, 110043]\n",
      "Substrate 37 AUPRC: 0.1716, AUC: 0.3811\n",
      "Proteins: [143347, 209693, 186360, 86234, 5137, 124045, 61151, 152255, 108805, 36874]\n",
      "Substrate 38 AUPRC: 0.0554, AUC: 0.2380\n",
      "Proteins: [18694, 126]\n",
      "Substrate 39 AUPRC: 0.0140, AUC: 0.3200\n",
      "Proteins: [135289, 33293, 44662, 89391, 127642, 46301, 102943, 124429, 77562, 80515, 89202, 131382]\n",
      "Substrate 40 AUPRC: 0.0654, AUC: 0.2375\n",
      "Proteins: [139703, 182606]\n",
      "Substrate 41 AUPRC: 0.0571, AUC: 0.8500\n",
      "Proteins: [50087, 78357]\n",
      "Substrate 42 AUPRC: 0.0103, AUC: 0.0700\n",
      "Proteins: [59235]\n",
      "Substrate 43 AUPRC: 0.0050, AUC: 0.0100\n",
      "Proteins: [97380, 80279, 184809]\n",
      "Substrate 44 AUPRC: 0.0256, AUC: 0.4633\n",
      "Proteins: [149800]\n",
      "Substrate 46 AUPRC: 0.0227, AUC: 0.7900\n",
      "Proteins: [28818]\n",
      "Substrate 47 AUPRC: 0.0172, AUC: 0.7200\n",
      "Proteins: [21763, 23109, 172679, 106953, 2800, 82609, 91499, 185149, 103371]\n",
      "Substrate 48 AUPRC: 0.0713, AUC: 0.4567\n",
      "Proteins: [11442]\n",
      "Substrate 49 AUPRC: 0.0053, AUC: 0.0700\n",
      "Proteins: [64979]\n",
      "Substrate 51 AUPRC: 0.0075, AUC: 0.3400\n",
      "Proteins: [133937, 53513, 40218]\n",
      "Substrate 52 AUPRC: 0.0174, AUC: 0.2133\n",
      "Proteins: [240, 127140, 3353, 162341]\n",
      "Substrate 53 AUPRC: 0.0219, AUC: 0.1725\n",
      "Proteins: [187903, 95349, 203401, 42135, 127342, 156865, 144238, 122512, 97584, 187851, 86834, 90311, 26537, 118470, 146276, 116994, 111071, 131823, 134527, 183939, 103695, 110923, 148784, 78443, 78400, 110162, 144462, 129566, 80842, 113846, 107604, 201172, 199609, 171825, 123194, 201167, 93616, 78414, 130677, 124466, 148110, 117298, 8925, 193164, 111468, 83090, 149810, 172678, 185537, 155350, 98818, 184808, 172110, 179476, 227732, 117330, 95377, 73289, 183942, 108584, 106134, 89599, 4112, 17171, 109294, 80321, 187834, 148773, 25767, 136510, 74208, 90035, 6361, 231264, 52327, 144868, 124497, 119961, 61699, 82881, 148786, 103399, 28772, 156344, 111808, 199980, 89999, 193805, 61146, 153806, 115809, 96005, 33515, 174971, 138109, 130416, 85660, 91754, 117331, 113592, 99384, 92542, 200828, 152489, 138434, 174333, 184304, 181247, 120864, 201206, 81255, 106135, 78330, 149163, 16838, 121057, 181737, 109455, 80795, 143736, 93121, 82425, 93102, 103075, 97656, 124464, 127336, 116921, 184803, 201144, 102536, 111393, 81117, 198409, 89649, 44662, 93119, 104996, 83463, 117372, 93086, 111385, 104993, 129685, 117384, 202860, 130419, 220798, 140286, 153800, 80147, 149068, 7064, 127438, 103232, 119064, 87073, 143001, 96118, 205363, 135647, 165925, 7635, 201158, 184696, 93076, 98220, 89036, 152599, 187359, 222372, 93443, 111483, 96223, 148747, 89424, 134492, 95380, 110894, 134681, 172509, 149159, 167426, 83458, 96106, 90089, 115810, 96170, 149060, 109013, 80920, 138322, 82121, 92572, 106, 139254, 140026, 161471, 96110, 100113, 233164, 4213, 130418, 20213, 138429, 71845, 183704, 82150, 82702, 222849, 190550, 90312, 93120, 201155, 120615, 115791, 101112, 181819, 175411, 134489, 220046, 124463, 179473, 198407, 92560, 193793, 152730, 220897, 107654, 78423, 86727, 150251, 176441, 193115, 124468, 110702, 130657, 130310, 201180, 183925, 79813, 157179, 122651, 81929, 149067, 115803, 91940, 99836, 144245, 104816, 81609, 147899, 185493, 189653, 231547, 114123, 183937, 115799, 78151, 184196, 159410, 94941, 205568, 185685, 144923, 104562, 180419, 154374, 104564, 3286, 155322, 102938, 86058, 139690, 152484, 154647, 86244, 106298, 39277, 93101, 224293, 143747, 231852, 92547, 148534, 122032, 184800, 121086, 106442, 233160, 139737, 228662, 104150, 208225, 178020, 106962, 46078, 98122, 100119, 114070, 183929, 125092, 154620, 25338, 184795, 153817, 105458, 178698, 82151, 146494, 188634, 176538, 111693, 178562, 88884, 168352, 35572, 133774, 118946, 225771, 201188, 127340, 17199, 103242, 202842, 201170, 82836, 204638, 159390, 153290, 226555, 78343, 150239, 48905, 205364, 111555, 111826, 180416, 116260, 113774, 117789, 122920, 101116, 149158, 152575, 185534, 77617, 181245, 161949, 102948, 201151, 53737, 86225, 149987, 167001, 140064, 155343, 149017, 214805, 18427, 74992, 80786, 172114, 150222, 97208, 118950, 153295, 181853, 98327, 91779, 148754, 181852, 127139, 117363, 172507, 114230, 89288, 77980, 107964, 205365, 175764]\n",
      "Substrate 54 AUPRC: 0.7062, AUC: 0.2744\n",
      "Proteins: [28544]\n",
      "Substrate 55 AUPRC: 0.0066, AUC: 0.2500\n",
      "Proteins: [151650, 863, 141363]\n",
      "Substrate 56 AUPRC: 0.0175, AUC: 0.2233\n",
      "Proteins: [19463, 201982, 84230, 132652]\n",
      "Substrate 58 AUPRC: 0.0266, AUC: 0.2725\n",
      "Proteins: [114674, 83445, 20085, 37184, 19463]\n",
      "Substrate 59 AUPRC: 0.0276, AUC: 0.1920\n",
      "Proteins: [156345, 154375]\n",
      "Substrate 60 AUPRC: 0.0260, AUC: 0.4800\n",
      "Proteins: [114548, 46301, 113127]\n",
      "Substrate 61 AUPRC: 0.0179, AUC: 0.2467\n",
      "Proteins: [89080, 11611]\n",
      "Substrate 62 AUPRC: 0.0104, AUC: 0.0850\n",
      "Proteins: [61495, 89415, 111812, 111838, 109054, 86724, 88420, 107507, 144120, 181791, 89005, 17045, 108586, 163097, 113409, 129166, 89962, 172681, 116746, 167503, 1579, 89447, 74213, 110981, 98117, 133355, 156889, 115809, 97217, 128673, 118787, 164696, 173811, 57153, 101928, 89164, 91066, 89961, 87513, 86057, 219355, 63829, 89595, 156465, 133569, 87071, 89885, 110139, 143681, 147586, 100225, 77635, 122924, 115098, 166016, 128983, 110154, 138934, 114964, 77637, 39277, 152623, 80256, 104553, 97637, 148776, 118119, 81014, 89390, 147564, 61570, 162974, 138882, 136726, 131224, 231548, 209384, 143076, 12576, 222370, 88645, 88881, 121323, 73985, 150068, 84993, 98070, 176096, 89634, 86458, 134680, 47591, 82413, 77612, 62462, 126564, 111834, 138437, 142638, 128638, 76951, 74924, 83445, 88927, 83949, 75424, 197321, 116993, 97565, 72984, 85052, 73383, 91876, 143659, 181255, 97176, 82978, 174820, 82423, 102472, 120848, 91055, 218772, 93123, 73379, 84809, 104778, 73918, 124048, 89629, 80224, 199612, 73887, 167423, 132610, 86516, 124237, 120219, 18764, 18667, 121096, 162976, 463, 145555, 201348, 109040, 85451, 183939, 117272, 109211, 101447, 129289, 86449, 202841, 9391, 78231, 106998, 193115, 85920, 68019, 118116, 144117, 89282, 167427, 89366, 89605, 140388, 76111, 119949, 128227, 143695, 86385, 80321, 8227, 133316, 89204, 85662, 15131, 111692, 89084, 113623, 91771, 76423, 82572, 73294, 172022, 80104, 153823, 132284, 159507, 86514, 113845, 109294, 97598, 80226, 121111, 106280, 140264, 88416, 70300, 145557, 78398, 113107, 92534, 25758, 88384, 78868, 130740, 173470, 85640, 129732, 52722, 132282, 101926, 77768, 107622, 89636, 183926, 92578, 91493, 148786, 16397, 140270, 89002, 106382, 113642, 32939, 35351, 141814, 98809, 115270, 151633, 82560, 88207, 175620, 181783, 150271, 82871, 80922, 173833, 171686, 105334, 134231, 160756, 88840, 118807, 96087, 104988, 108163, 194865, 142635, 205362, 146494, 183778, 86068, 179472, 93629, 193792, 212764, 129578, 152575, 105801, 190086, 156652, 6125, 132105, 87872, 63553, 70558, 36874, 171147, 76928, 78099, 116291, 155370, 89610, 82121, 162341, 116292, 125937, 28510, 132609, 74858, 70509, 96004, 58056, 174540, 107516, 157648, 74046, 91202, 139298, 134828, 229966, 141113, 143148, 147134, 80631, 130512, 162340, 187850, 78836, 85479, 129290, 128675, 165837, 3286, 164103, 104782, 113405, 76939, 92569, 116832, 135793, 122197, 79813, 121457, 8338, 128360, 138271, 207423, 88841, 149707, 88878, 111819, 114226, 75909, 116259, 121431, 117668, 165397, 122932, 143765, 158824, 174731, 80307, 73885, 76935, 150764, 124250, 91064, 114250, 85477, 173533, 28712, 113514, 83999, 174431, 225912, 84000, 138776, 29450, 159244, 101922, 158089, 485, 134678, 130836, 90016, 88345, 97688, 97604, 114723, 77613, 81267, 110581, 81243, 130682, 101356, 191199, 73124, 95376, 102957, 140265, 91336, 149808, 84158, 88879, 110233, 172312, 198200, 91763, 50323, 95531, 88410, 97224, 85647, 85053, 93077, 111067, 227718, 89631, 91764, 127056, 97640, 80747, 73814, 98536, 89669, 85976, 12581, 87224, 91065, 139572, 143739, 85608, 132619, 90850, 115703, 9134, 93085, 118897, 156892, 99334, 11611, 121939, 89311, 80969, 8482, 77640, 88890, 19992, 182604, 110151, 99362, 124467, 82418, 209950, 81785, 127259, 181256, 13904, 83988, 121298, 101923, 175394, 149981, 122920, 178573, 145392, 160809, 119002, 111469, 83691, 97691, 116028, 119335, 111226, 110358, 202842, 158825, 17200, 83998, 39269, 76469, 115080, 142033, 100163, 94432, 82917, 85001, 127255, 139570, 110087, 156406, 132072, 161147, 98509, 86451, 76080, 85530, 91338, 89200, 140087, 114721, 209062, 135027, 91411, 106139, 97655, 25468, 136274, 131778, 129401, 94433, 129400, 86252, 90053, 81700, 88896, 133399, 91762, 110659, 73988, 116999, 124232, 175412, 88208, 135564, 77956, 101952, 173831, 140071, 113567, 129580, 218644, 137127, 188507, 76907, 50306, 104780, 68125, 65312, 106592, 8342, 80959, 85757, 73717, 233001, 95349, 81241, 159788, 171149, 156842, 84499, 91557, 117937, 150067, 89290, 75545, 82915, 89319, 129567, 93098, 91408, 41206, 135636, 85464, 200075, 161600, 170965, 174736, 88261, 91416, 45830, 104566, 84503, 117282, 89637, 95371, 162349, 7047, 85652, 81015, 119023, 105652, 157049, 192939, 91767, 93101, 85163, 115386, 139113]\n",
      "Substrate 63 AUPRC: 0.7477, AUC: 0.2568\n",
      "Proteins: [225304, 91937, 133225, 62746, 13741, 53892, 103892, 93858, 93441, 104154, 144298, 176094, 103891, 18830, 82101]\n",
      "Substrate 64 AUPRC: 0.0763, AUC: 0.1900\n",
      "Proteins: [124497, 132104, 150764, 115101, 7592, 86226, 115083, 76873, 193684, 78392, 134333, 139420, 72982, 82874, 74245, 86720, 26997, 34724, 78184, 183705, 21536, 154376, 10632, 109992, 89364, 163054, 144489, 75309, 82422, 105675, 155375, 111093, 142145, 130652, 49694, 140299, 94439, 169185, 84865, 96346, 1238, 111739, 163523, 90730, 149056, 91410, 121283, 88996, 78420, 141810, 84504, 86195, 149158, 116842, 14155, 142912, 42125, 114657, 114542, 53606, 187852, 114547, 190556, 153850, 117297, 86808, 87500, 84230, 107606, 140089, 87369, 117231, 107577, 199554, 87515, 136563, 143722, 153849, 132101, 110147, 111697, 74829, 101143, 109297, 76910, 140801, 96220, 78440, 187970, 117289, 5655, 121465, 53609, 106264, 162464, 132037, 143754, 122925, 74994, 78422, 77635, 117319, 122924, 117564, 78399, 98521, 153828, 106268, 106974, 80552, 80530, 130425, 81262, 106440, 111491, 108411, 97688, 82559, 28301, 191082, 97594, 114234, 113848, 170309, 32143, 86683, 133355, 119059, 118033, 185588, 230889, 143687, 78434, 78435, 187969, 90309, 199607, 105668, 108774, 142036, 89084, 41995, 88014, 105657, 151507, 171324, 78663, 88398, 89673, 117942, 143790, 97614, 74211, 126848, 39375, 141122, 81131, 161176, 134516, 108350, 91049, 91034, 89047, 89321, 136493, 97978, 98152, 138439, 117245, 137456, 96225, 78441, 72981, 78353, 77624, 97648, 117292, 114251, 143706, 46302, 110750, 91761, 120409, 96230, 156415, 87550, 76481, 86685, 86744, 119839, 132958, 98901, 104786, 97412, 170038, 171414, 82980, 143683, 143758, 106271, 182856, 164101, 177654, 132623, 143769, 85693, 86812, 89486, 111049, 114961, 107599, 146115, 62578, 78156, 135631, 134505, 168328, 152937, 26410, 77644, 80528, 132106, 76564, 191203, 167529, 132103, 102316, 1963, 133226, 97573, 123122, 198289, 85153, 78468, 118897, 98522, 32939, 114280, 96001, 147624, 106297, 137611, 103074, 80802, 88959, 88991, 48855, 125945, 118724, 105002, 169647, 139220, 136571, 153829, 129398, 88349, 116588, 172405, 84863, 117235, 53359, 106998, 150249, 113404, 80687, 146581, 194864, 97577, 112710, 105656, 34511, 86807, 26391, 142217, 97674, 7185, 106928, 81133, 87514, 137781, 97395, 85251, 74895, 78438, 126843, 87404, 135619, 76944, 130407, 97489, 155360, 149014, 97622, 175404, 201349, 111694, 145557, 183649, 97588, 88654, 86726, 8342, 85249, 224299, 201118, 89424, 26685, 78381, 205364, 143737, 192324, 1681, 121529, 81263, 78429, 153830, 28513, 135025, 115817, 110580, 53277, 17524, 5278, 97593, 87871, 21440, 114231, 78388, 119056, 85252, 86246, 123816, 111698, 97589, 114960, 117320, 143684, 155371, 228924, 144305, 74251, 97389, 29194, 171374, 78450, 109998, 104565, 109015, 153831, 1579, 148839, 189866]\n",
      "Substrate 65 AUPRC: 0.6419, AUC: 0.2347\n",
      "Proteins: [27016, 1606, 28712, 41187]\n",
      "Substrate 66 AUPRC: 0.0374, AUC: 0.5225\n",
      "Proteins: [85476]\n",
      "Substrate 67 AUPRC: 0.0051, AUC: 0.0300\n",
      "Proteins: [175875, 50656, 200827, 176111, 212280, 182856, 71845]\n",
      "Substrate 70 AUPRC: 0.0374, AUC: 0.1600\n",
      "Proteins: [175307, 132039, 33770, 26892, 76423, 88262, 132432, 203013]\n",
      "Substrate 71 AUPRC: 0.0442, AUC: 0.2175\n",
      "Proteins: [214435, 143786, 7592, 117563]\n",
      "Substrate 72 AUPRC: 0.0312, AUC: 0.4200\n",
      "Proteins: [41277, 192231, 150108, 41164, 4888, 55941, 107621, 86727, 120791, 103329, 122165]\n",
      "Substrate 73 AUPRC: 0.0606, AUC: 0.1809\n",
      "Proteins: [127905, 89376]\n",
      "Substrate 74 AUPRC: 0.0154, AUC: 0.4050\n",
      "Proteins: [89016]\n",
      "Substrate 75 AUPRC: 0.0051, AUC: 0.0200\n",
      "Proteins: [149022, 128688, 132608, 169288]\n",
      "Substrate 76 AUPRC: 0.0233, AUC: 0.2400\n",
      "Proteins: [34690, 142699, 85242, 55941, 144069, 208783, 85184, 114313, 181262, 113127, 18412, 90853, 85246, 128221, 89376, 66492, 35770, 67648, 144245, 123081, 175380, 55241, 103308]\n",
      "Substrate 78 AUPRC: 0.1104, AUC: 0.1774\n",
      "Proteins: [97641]\n",
      "Substrate 79 AUPRC: 0.0054, AUC: 0.0800\n",
      "Proteins: [173626, 90528, 81700, 131340, 55241, 130435, 64248]\n",
      "Substrate 81 AUPRC: 0.0438, AUC: 0.3000\n",
      "Proteins: [30982, 48390, 14636]\n",
      "Substrate 82 AUPRC: 0.0150, AUC: 0.0333\n",
      "Proteins: [95012]\n",
      "Substrate 83 AUPRC: 0.0074, AUC: 0.3300\n",
      "Proteins: [48390, 63518, 88013, 107522]\n",
      "Substrate 86 AUPRC: 0.0217, AUC: 0.1725\n",
      "Proteins: [88]\n",
      "Substrate 87 AUPRC: 0.0050, AUC: 0.0000\n",
      "Proteins: [215271, 35773, 37080, 15864, 21763, 20870, 117415]\n",
      "Substrate 88 AUPRC: 0.0460, AUC: 0.3343\n",
      "Proteins: [31722, 33242]\n",
      "Substrate 89 AUPRC: 0.0114, AUC: 0.1500\n",
      "Proteins: [1269, 31722, 39277]\n",
      "Substrate 90 AUPRC: 0.0166, AUC: 0.1800\n",
      "Proteins: [190225]\n",
      "Substrate 91 AUPRC: 0.0066, AUC: 0.2500\n",
      "Proteins: [114250, 152670, 33242, 132624, 78386]\n",
      "Substrate 92 AUPRC: 0.0316, AUC: 0.3060\n",
      "Proteins: [80320, 58, 114670]\n",
      "Substrate 95 AUPRC: 0.0186, AUC: 0.2733\n",
      "Proteins: [58, 150229]\n",
      "Substrate 96 AUPRC: 0.0100, AUC: 0.0300\n",
      "Proteins: [166831, 172929]\n",
      "Substrate 97 AUPRC: 0.0101, AUC: 0.0350\n",
      "Proteins: [132954]\n",
      "Substrate 99 AUPRC: 0.0135, AUC: 0.6400\n",
      "Proteins: [56874, 162974, 144016, 132627, 52916, 152910]\n",
      "Substrate 100 AUPRC: 0.0445, AUC: 0.4150\n",
      "Proteins: [92097, 103232, 88651]\n",
      "Substrate 101 AUPRC: 0.0159, AUC: 0.1400\n",
      "Proteins: [11484, 15171, 228859]\n",
      "Substrate 102 AUPRC: 0.0261, AUC: 0.3800\n",
      "Proteins: [86818, 176103]\n",
      "Substrate 103 AUPRC: 0.0150, AUC: 0.3850\n",
      "Proteins: [3286, 1579]\n",
      "Substrate 104 AUPRC: 0.0103, AUC: 0.0550\n",
      "Proteins: [362, 2479, 130321]\n",
      "Substrate 106 AUPRC: 0.0178, AUC: 0.2333\n",
      "Proteins: [188540]\n",
      "Substrate 107 AUPRC: 0.0056, AUC: 0.1100\n",
      "Proteins: [17165]\n",
      "Substrate 108 AUPRC: 0.0128, AUC: 0.6200\n",
      "Proteins: [32837, 646]\n",
      "Substrate 111 AUPRC: 0.0126, AUC: 0.2300\n",
      "Proteins: [10022, 91412]\n",
      "Substrate 112 AUPRC: 0.0132, AUC: 0.2950\n",
      "Proteins: [214425, 148753, 88358, 80787, 6283, 85777]\n",
      "Substrate 113 AUPRC: 0.0324, AUC: 0.1683\n",
      "Proteins: [179474, 106294, 97592, 34115, 101925, 111439, 178018]\n",
      "Substrate 119 AUPRC: 0.0516, AUC: 0.3614\n",
      "Proteins: [86293, 89356, 1469, 56142]\n",
      "Substrate 120 AUPRC: 0.0219, AUC: 0.1575\n",
      "Proteins: [35611]\n",
      "Substrate 121 AUPRC: 0.0114, AUC: 0.5700\n",
      "Proteins: [15133, 30966, 146180, 145908, 35611, 171363]\n",
      "Substrate 122 AUPRC: 0.0312, AUC: 0.1450\n",
      "Proteins: [15133, 3285]\n",
      "Substrate 124 AUPRC: 0.0122, AUC: 0.2350\n",
      "Proteins: [108778]\n",
      "Substrate 125 AUPRC: 0.0098, AUC: 0.5000\n",
      "Proteins: [850, 32939]\n",
      "Substrate 126 AUPRC: 0.0231, AUC: 0.5850\n",
      "Proteins: [75997, 227586, 89631, 87077]\n",
      "Substrate 129 AUPRC: 0.0219, AUC: 0.1825\n",
      "Proteins: [116940, 156649, 139841, 74737, 178338, 130677, 6058, 222812, 147564, 204224, 106915, 130472, 89666, 39277, 139261, 28718, 225006, 8805, 205568, 140082, 114305, 105456, 85161, 165923, 74357, 204715, 166146, 222725, 153816, 113916, 118783, 205757, 177653, 161589, 205157, 229966, 172149, 108805, 175407, 109744, 76483, 171324, 175782, 114680, 3904, 174822, 158564, 163595, 98901, 118609]\n",
      "Substrate 132 AUPRC: 0.2199, AUC: 0.2252\n",
      "Proteins: [172405, 220897, 77038, 143096, 88422, 159240, 94969, 113232, 103284, 89185, 168726, 157753, 135539, 47909, 165924, 87544, 222370, 20870, 189584, 85046, 175781, 110096, 89635, 29194, 145065, 214099, 176114, 127143, 220077, 86066, 134860, 163308, 222812, 176097, 79265, 106949, 111838]\n",
      "Substrate 133 AUPRC: 0.2041, AUC: 0.3295\n",
      "Proteins: [8925, 3904, 17542]\n",
      "Substrate 134 AUPRC: 0.0178, AUC: 0.2233\n",
      "Proteins: [78415]\n",
      "Substrate 137 AUPRC: 0.0074, AUC: 0.3300\n",
      "Proteins: [161589]\n",
      "Substrate 138 AUPRC: 0.0067, AUC: 0.2600\n",
      "Proteins: [101952]\n",
      "Substrate 140 AUPRC: 0.0051, AUC: 0.0300\n",
      "Proteins: [125516]\n",
      "Substrate 141 AUPRC: 0.0139, AUC: 0.6500\n",
      "Proteins: [5137, 29296]\n",
      "Substrate 142 AUPRC: 0.0174, AUC: 0.4400\n",
      "Proteins: [32693, 40791, 171421, 137608]\n",
      "Substrate 143 AUPRC: 0.0220, AUC: 0.1775\n",
      "Proteins: [105460, 8838]\n",
      "Substrate 144 AUPRC: 0.0101, AUC: 0.0350\n",
      "Proteins: [128694, 109015, 27878]\n",
      "Substrate 145 AUPRC: 0.0194, AUC: 0.3100\n",
      "Proteins: [25376]\n",
      "Substrate 146 AUPRC: 0.0053, AUC: 0.0700\n",
      "Proteins: [80795, 25184]\n",
      "Substrate 147 AUPRC: 0.0111, AUC: 0.1600\n",
      "Proteins: [107011]\n",
      "Substrate 148 AUPRC: 0.0051, AUC: 0.0200\n",
      "Proteins: [130647]\n",
      "Substrate 149 AUPRC: 0.0050, AUC: 0.0100\n",
      "Proteins: [121088, 86223, 189870, 109086, 72845, 51113, 85789, 113405, 98902, 115454, 137714, 53513, 15889]\n",
      "Substrate 155 AUPRC: 0.0715, AUC: 0.2446\n",
      "Proteins: [183113, 30300]\n",
      "Substrate 156 AUPRC: 0.0100, AUC: 0.0150\n",
      "Proteins: [14602]\n",
      "Substrate 158 AUPRC: 0.0085, AUC: 0.4200\n",
      "Proteins: [5969]\n",
      "Substrate 167 AUPRC: 0.0052, AUC: 0.0500\n",
      "Proteins: [72983]\n",
      "Substrate 174 AUPRC: 0.0052, AUC: 0.0400\n",
      "Average AUPRC across all substrates: 0.0611\n",
      "Average AUC across all substrates: 0.2551\n"
     ]
    }
   ],
   "source": [
    "# Function to load the model and run AUPRC and AUC testing\n",
    "def run_auprc_auc_testing(model_path, x_dict, edge_index_dict, test_edges_tp_s, protein_df, device):\n",
    "    # Load the best model\n",
    "    model = GCNLinkPredictor(protein_dim=2048, substrate_dim=2048, hidden_channels=64).to(device)  # Adjust model params\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # New AUPRC and AUC testing per substrate\n",
    "    true_positive_edges = test_edges_tp_s  # Make sure this variable holds valid test edges\n",
    "\n",
    "    # Evaluate AUPRC and AUC for each unique substrate\n",
    "    results = evaluate_all_substrates(model, x_dict, edge_index_dict, true_positive_edges, protein_df, device)\n",
    "\n",
    "    # Print average AUPRC and AUC across all substrates\n",
    "    avg_auprc = np.mean([res['auprc'] for res in results.values()])\n",
    "    avg_auc = np.mean([res['auc'] for res in results.values()])\n",
    "    print(f\"Average AUPRC across all substrates: {avg_auprc:.4f}\")\n",
    "    print(f\"Average AUC across all substrates: {avg_auc:.4f}\")\n",
    "\n",
    "    return results, avg_auprc, avg_auc\n",
    "\n",
    "# AUPRC and AUC evaluation functions\n",
    "def evaluate_all_substrates(model, x_dict, edge_index_dict, true_positive_edges, protein_df, device):\n",
    "    unique_substrates = true_positive_edges[1].unique().tolist()\n",
    "    \n",
    "    substrate_metrics = {}\n",
    "    \n",
    "    for substrate in unique_substrates:\n",
    "        auprc, auc_score, precision, recall, fpr, tpr = evaluate_substrate_auprc_auc(\n",
    "            model, x_dict, edge_index_dict, substrate, true_positive_edges, protein_df, device\n",
    "        )\n",
    "        substrate_metrics[substrate] = {'auprc': auprc, 'auc': auc_score}\n",
    "        print(f\"Substrate {substrate} AUPRC: {auprc:.4f}, AUC: {auc_score:.4f}\")\n",
    "    \n",
    "    return substrate_metrics\n",
    "\n",
    "# Function to calculate both AUPRC and AUC for a given substrate\n",
    "def evaluate_substrate_auprc_auc(model, x_dict, edge_index_dict, substrate_index, true_positive_edges, protein_df, device, seed=42):\n",
    "    np.random.seed(seed)  # Set seed for reproducibility\n",
    "\n",
    "    # Get all associated transporter proteins (positive edges)\n",
    "    mask = true_positive_edges[1] == substrate_index  # Mask for the current substrate\n",
    "    pos_proteins = true_positive_edges[0][mask].tolist()  # Get the corresponding transporter proteins\n",
    "    print(f\"Proteins: {pos_proteins}\")\n",
    "\n",
    "    # Generate 100 negative edges (proteins not linked to this substrate)\n",
    "    all_proteins = list(range(len(protein_df)))  # Assuming protein_df index corresponds to protein indices\n",
    "    neg_proteins = np.random.choice(list(set(all_proteins) - set(pos_proteins)), size=100, replace=False)\n",
    "\n",
    "    # Create edges: positive and negative\n",
    "    test_edges = torch.cat([torch.tensor(pos_proteins).unsqueeze(0),\n",
    "                            torch.full((1, len(pos_proteins)), substrate_index)], dim=0)\n",
    "    neg_edges = torch.cat([torch.tensor(neg_proteins).unsqueeze(0),\n",
    "                           torch.full((1, len(neg_proteins)), substrate_index)], dim=0)\n",
    "\n",
    "    # Combine positive and negative edges\n",
    "    all_edges = torch.cat([test_edges, neg_edges], dim=1)\n",
    "    \n",
    "    # Create labels: 1 for positive edges, 0 for negative edges\n",
    "    labels = torch.cat([torch.ones(len(pos_proteins)), torch.zeros(100)])\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        preds = model(x_dict, edge_index_dict, all_edges)\n",
    "\n",
    "    # Calculate precision-recall curve and AUPRC\n",
    "    precision, recall, _ = precision_recall_curve(labels.cpu().numpy(), torch.sigmoid(preds).cpu().numpy())\n",
    "    auprc_value = auc(recall, precision)  # Calculate AUPRC\n",
    "\n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(labels.cpu().numpy(), torch.sigmoid(preds).cpu().numpy())\n",
    "    auc_value = auc(fpr, tpr)  # Calculate AUC\n",
    "\n",
    "    return auprc_value, auc_value, precision, recall, fpr, tpr\n",
    "\n",
    "# Run the AUPRC and AUC testing\n",
    "model_path = '/data/servilla/DT_HGNN/data/Models_saves/best_model.pth'  # Path to your saved model\n",
    "device = torch.device('cpu')  # Temporarily switch to CPU\n",
    "\n",
    "# Assuming `data` contains x_dict and edge_index_dict\n",
    "x_dict = data.x_dict\n",
    "edge_index_dict = data.edge_index_dict\n",
    "\n",
    "# Assuming test_edges_tp_s and p_df are already defined\n",
    "\n",
    "# Call the function to run AUPRC and AUC testing\n",
    "results, avg_auprc, avg_auc = run_auprc_auc_testing(model_path, x_dict, edge_index_dict, test_edges_tp_s, p_df, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional: Visualize AUPRC for each substrate (example)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Create lists for substrates and AUPRC values\n",
    "substrates = list(auprcs.keys())\n",
    "auprc_values = list(auprcs.values())\n",
    "\n",
    "# Plot the AUPRC values\n",
    "plt.scatter(substrates, auprc_values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Substrate Index')\n",
    "plt.ylabel('AUPRC')\n",
    "plt.title('AUPRC for Each Substrate')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming you have the following data:\n",
    "# - auprcs: a dictionary containing AUPRC values for each substrate\n",
    "# - class_counts: a dictionary containing the count of occurrences for each substrate\n",
    "# Get the substrate indices (second row of the edges tensor)\n",
    "substrates_in_edges = test_edges_tp_s[1].tolist()  # Convert tensor to a list\n",
    "\n",
    "# Count occurrences of each substrate\n",
    "class_counts = Counter(substrates_in_edges)\n",
    "# Convert AUPRC values and class counts to lists\n",
    "auprc_values = list(auprcs.values())\n",
    "class_count_values = list(class_counts.values())\n",
    "\n",
    "# Compute the log10 of class counts for the x-axis\n",
    "log_class_count = np.log10(class_count_values)\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(log_class_count, auprc_values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Log10 Class Count')\n",
    "plt.ylabel('AUPRC')\n",
    "plt.title('AUPRC vs. Log10 Class Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_s_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tp_s_test_df = tp_s_test_df[tp_s_test_df['label'] == 1]\n",
    "positive_tp_s_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_set = set(positive_tp_s_test_df['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_targets = positive_tp_s_test_df.groupby(['target'])\n",
    "len(grouped_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_value in target_set:\n",
    "    substrate_group = grouped_targets.get_group(target_value)\n",
    "    print(f\"{substrate_group}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
